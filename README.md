# ğŸ§  DataNeuron

**Intelligent Document AI Agent with Multi-Step Reasoning**

DataNeuron is an advanced AI agent that transforms your documents into intelligent conversation partners. Unlike basic RAG systems, DataNeuron employs multi-step reasoning, tool-based architecture, and semantic intelligence to provide comprehensive document analysis and insights.

## âœ¨ Key Features

### ğŸ¤– Multi-Step Reasoning AI Agent
- **Complex query decomposition** into manageable steps
- **Tool chain planning** with sequential execution
- **Context-aware processing** where each tool builds on previous results
- **Smart commentary** throughout the analysis process

### ğŸ“„ Hybrid Document Processing
- **Multi-format support**: PDF, TXT, DOCX
- **Smart routing**: Small documents use full-text search, large documents use vector search
- **Anti-hallucination measures** with source attribution
- **Document persistence** with session management

### ğŸ› ï¸ Extensible Tool Ecosystem
- **Document tools**: Read, search, summarize, compare documents
- **Web research tools**: Search, verify information, get industry benchmarks
- **Analysis tools**: Extract insights, generate risk assessments
- **Semantic tools**: Query expansion, domain detection

### ğŸ§  Semantic Intelligence
- **Query expansion**: "fesih" â†’ "sona erme, iptal, terminate, sonlandÄ±rma"
- **Domain-aware processing**: Legal, financial, technical terminology
- **Multilingual support**: Turkish â†” English semantic mapping
- **Context recognition**: Document type detection and optimization

### ğŸ¨ Professional User Interface
- **ChatGPT-style interface** with real-time tool tracking
- **Session management** with document continuity options
- **Sidebar document manager** for file organization
- **Smart error handling** with user-friendly messages

## ğŸš€ Quick Start

### Prerequisites
- Python 3.9+
- OpenAI API key

### Installation

1. **Clone the repository**
```bash
git clone https://github.com/yourusername/dataneuron.git
cd dataneuron
```

2. **Install dependencies**
```bash
pip install -r requirements.txt
```

3. **Set up environment variables**
```bash
cp .env.example .env
# Edit .env with your API keys
```

4. **Run the application**
```bash
python main.py
```

The application will start on `http://localhost:8501`

## âš™ï¸ Configuration

### Environment Variables

Create a `.env` file based on `.env.example`:

```bash
# OpenAI Configuration
OPENAI_API_KEY=your_openai_api_key_here
OPENAI_MODEL=gpt-3.5-turbo

# ChromaDB Configuration
CHROMADB_PATH=./data/chroma_db
CHROMADB_COLLECTION=dataneuron_docs

# Web Search (Optional)
SERPAPI_KEY=your_serpapi_key_here

# Logging
LOG_LEVEL=INFO
LOG_FILE=./logs/dataneuron.log

# Streamlit
STREAMLIT_PORT=8501
```

### Model Configuration

DataNeuron supports multiple OpenAI models:
- `gpt-3.5-turbo` (default, cost-effective)
- `gpt-4` (enhanced reasoning, higher cost)
- `gpt-4-turbo` (latest features)

## ğŸ’¡ Usage Examples

### Basic Document Analysis
```
User: "Bu PDF'yi Ã¶zetle"
DataNeuron: "Belgenizi analiz ediyorum..." 
â†’ read_full_document() â†’ comprehensive summary with insights
```

### Complex Multi-Document Analysis
```
User: "Bu 3 ÅŸirketin mali tablolarÄ±nÄ± karÅŸÄ±laÅŸtÄ±r ve sektÃ¶r ortalamasÄ±yla kÄ±yasla"
DataNeuron: Multi-step execution:
1. read_full_document() Ã— 3
2. compare_documents()
3. search_web() for industry benchmarks
4. synthesize_multi_tool_results()
â†’ Comprehensive comparative analysis
```

### Legal Document Review
```
User: "Bu sÃ¶zleÅŸmede riskli maddeler var mÄ±?"
DataNeuron: 
1. analyze_document_domain() â†’ "Legal contract detected"
2. search_in_document("ceza, sorumluluk, fesih") â†’ Semantic expansion
3. search_web() for industry standards
4. generate_risk_assessment()
â†’ Risk analysis with recommendations
```

## ğŸ—ï¸ Architecture

### Core Components

- **LLM Agent** (`core/llm_agent.py`): Multi-step reasoning engine
- **Tool Manager** (`core/tool_manager.py`): Tool orchestration and execution
- **Document Processor** (`core/document_processor.py`): Multi-format file reading
- **Session Manager** (`core/session_manager.py`): Document persistence
- **Vector Store** (`core/vector_store.py`): ChromaDB integration

### Tool Categories

1. **Document Tools**: Core document operations
2. **Web Tools**: External research capabilities
3. **Analysis Tools**: Advanced analytics and synthesis
4. **Semantic Tools**: Intelligence enhancement

### Data Flow

```
User Query â†’ LLM Agent â†’ Tool Chain Planning â†’ Sequential Execution â†’ Result Synthesis â†’ Smart Commentary â†’ User Response
```

## ğŸ§ª Testing

### Run All Tests
```bash
pytest tests/ -v
```

### Run Specific Test Categories
```bash
# Core functionality tests
pytest tests/test_document_processor.py -v
pytest tests/test_tool_manager.py -v
pytest tests/test_session_manager.py -v

# Integration tests
pytest tests/integration_tests.py -v
```

### Test Coverage
```bash
pytest --cov=dataneuron tests/
```

## ğŸ“Š Performance

### Optimization Features
- **Smart document routing**: Avoids unnecessary chunking for small documents
- **Caching**: Repeated queries use cached results
- **Parallel processing**: Multiple tools can run concurrently where possible
- **Resource management**: Memory-efficient processing for large documents

### Benchmarks
- **Small documents** (â‰¤10 pages): ~2-5 seconds response time
- **Large documents** (>10 pages): ~5-15 seconds for initial processing
- **Multi-tool chains**: ~10-30 seconds depending on complexity
- **Web integration**: +3-8 seconds for external research

## ğŸ”’ Security & Privacy

### Data Protection
- **Local processing**: Documents processed locally
- **No data retention**: No user data stored on external servers
- **API key encryption**: Secure credential management
- **Session isolation**: User data isolated between sessions

### Best Practices
- Store API keys in environment variables
- Regularly rotate API keys
- Use HTTPS in production deployments
- Monitor API usage and costs

## ğŸ›£ï¸ Roadmap

### V1.0 (Current)
- âœ… Multi-step reasoning engine
- âœ… Hybrid document processing
- âœ… Basic tool ecosystem
- âœ… Session management
- âœ… Semantic intelligence

### V1.5 (Coming Soon)
- ğŸ”„ Advanced semantic expansion
- ğŸ”„ Multi-language document support
- ğŸ”„ Performance optimizations
- ğŸ”„ Enhanced web research
- ğŸ”„ Custom domain terminologies

### V2.0 (Future)
- ğŸš€ Image generation tools (DALL-E integration)
- ğŸš€ Presentation creation tools
- ğŸš€ Excel/CSV analysis tools
- ğŸš€ Email automation tools
- ğŸš€ Calendar integration tools

### Enterprise Features (Future)
- ğŸ¢ Multi-tenant architecture
- ğŸ¢ Role-based access control
- ğŸ¢ Audit logging
- ğŸ¢ Custom model fine-tuning
- ğŸ¢ On-premise deployment

## ğŸ¤ Contributing

We welcome contributions! Please see our contributing guidelines:

### Development Setup
1. Fork the repository
2. Create a feature branch
3. Install development dependencies: `pip install -r requirements-dev.txt`
4. Make your changes
5. Run tests: `pytest`
6. Submit a pull request

### Code Standards
- **PEP 8** compliance
- **Type hints** for all functions
- **Docstrings** for all public methods
- **Unit tests** for new features
- **Integration tests** for new workflows

## ğŸ“ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

## ğŸ†˜ Support

### Getting Help
- **Documentation**: Check this README and code comments
- **Issues**: Report bugs on GitHub Issues
- **Discussions**: Join GitHub Discussions for questions

### Common Issues

**API Key Errors**
```
Error: OpenAI API key not found
Solution: Ensure OPENAI_API_KEY is set in your .env file
```

**Memory Issues with Large Documents**
```
Error: Memory allocation failed
Solution: Process documents in smaller chunks or increase system memory
```

**ChromaDB Persistence Issues**
```
Error: ChromaDB collection not found
Solution: Check CHROMADB_PATH permissions and restart application
```

## ğŸ™ Acknowledgments

- **OpenAI** for GPT models and embeddings API
- **ChromaDB** for vector storage capabilities
- **Streamlit** for the user interface framework
- **LangChain** for text processing utilities

## ğŸ“ˆ Unique Value Proposition

### What DataNeuron IS:
- **Multi-Step Reasoning AI Agent** â†’ Complex query decomposition and systematic analysis
- **Context-Aware Tool Orchestrator** â†’ Tools work together with shared context
- **Intelligent Document Consultant** â†’ Understands, analyzes, and recommends
- **Semantic-Aware AI Partner** â†’ Grasps language nuances and domain expertise
- **Extensible Intelligence Platform** â†’ Continuously growing capabilities

### What DataNeuron is NOT:
- Basic PDF reader/search tool
- Static Q&A system
- Embedding-dependent solution
- Single-purpose utility
- Simple RAG implementation

**DataNeuron transforms your documents from static files into intelligent conversation partners that understand context, provide insights, and reason through complex queries just like a human expert would.**

---

*Built with â¤ï¸ for intelligent document analysis*